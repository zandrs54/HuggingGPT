/**
 * ChatBot class for managing conversations and interactions with models on Hugging Face.
 */
export default class ChatBot {
    private cookie;
    private currentConversionID;
    private chatLength;
    private models;
    private headers;
    private currentModel;
    /**
     * Constructs a new instance of the ChatBot class.
     * @param {string} cookie - The user's authentication cookie.
     * @param {string} path - The path to a file containing the authentication cookie.
     * @throws {Error} If both `cookie` and `path` are provided or if neither is provided.
     */
    constructor(cookie?: string, path?: string);
    /**
     * Switches the active model for the chat.
     * @param {'meta-llama/Llama-2-70b-chat-hf' | 'codellama/CodeLlama-34b-Instruct-hf' |'mistralai/Mistral-7B-Instruct-v0.1'|'mistralai/Mistral-7B-Instruct-v0.2' |'NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO'|'openchat/openchat-3.5-0106'} value - The model to switch to.
     */
    switchModel(value: "meta-llama/Llama-2-70b-chat-hf" | "codellama/CodeLlama-34b-Instruct-hf" | "mistralai/Mistral-7B-Instruct-v0.1" | "mistralai/Mistral-7B-Instruct-v0.2" | "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO" | "openchat/openchat-3.5-0106"): void;
    /**
     * Lists available models that can be used with the chat.
     * @returns {string[]} An array of available model names.
     */
    listAvilableModels(): string[];
    /**
     * Reads cookies from a file path and sets them for authentication.
     * @param {string} path - The path to the file containing cookies.
     * @throws {Error} If `path` is undefined or if there is an error reading the file.
     */
    private readCookiesFromPath;
    /**
     * Initializes a new chat conversation.
     * @returns {Promise<string>} The conversation ID of the new chat.
     * @throws {Error} If the creation of a new conversation fails.
     */
    getNewChat(): Promise<string>;
    /**
     * Checks if there is an active conversation ID, and if not, creates a new chat.
     */
    private checkConversionId;
    /**
     * Initiates a chat with the provided text.
     * @param {string} text - The user's input text or prompt.
     * @param {string} currentConversionID - The conversation ID for the current chat.
     * @param {number} temperature - Temperature for text generation.
     * @param {number} truncate - Maximum number of tokens in the generated response.
     * @param {number} max_new_tokens - Maximum number of new tokens to generate.
     * @param {number} top_p - Top-p value for text generation.
     * @param {number} repetition_penalty - Repetition penalty for generated text.
     * @param {number} top_k - Top-k value for text generation.
     * @param {boolean} return_full_text - Whether to return the full text of the conversation.
     * @param {boolean} stream - Whether to use streaming for text generation.
     * @param {boolean} use_cache - Whether to use cached results for text generation.
     * @param {boolean} is_retry - Whether the request is a retry.
     * @returns {Promise<ChatResponse>} An object containing conversation details.
     * @throws {Error} If there is an issue with the chat request.
     */
    chat(text: string, currentConversionID?: string, temperature?: number, truncate?: number, max_new_tokens?: number, top_p?: number, repetition_penalty?: number, top_k?: number, return_full_text?: boolean, stream?: boolean, use_cache?: boolean, is_retry?: boolean): Promise<{
        id: string;
        stream: ReadableStream | undefined;
        completeResponsePromise: () => Promise<string>;
    }>;
    /**
     * Summarizes the conversation based on its conversation ID.
     * @param {string} conversation_id - The conversation ID to summarize.
     * @returns {Promise<any>} A Promise that resolves to the summarized conversation.
     * @throws {Error} If there is an issue summarizing the conversation.
     */
    private summarizeConversation;
    /**
     * Preserves the context of the current chat conversation.
     * @param {boolean} newChat - Indicates if a new chat is being preserved.
     * @returns {Promise<Response>} A Promise that resolves to the response from preserving chat context.
     * @throws {Error} If there is an issue preserving chat context.
     */
    private preserveContext;
}
//# sourceMappingURL=chat.d.ts.map